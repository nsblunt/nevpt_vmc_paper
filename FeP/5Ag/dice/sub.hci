#!/bin/bash
#SBATCH -J hci
#SBATCH -p LONG
#SBATCH --time=48:00:00
#SBATCH -C new
#SBATCH -n80

wd=$SLURM_SUBMIT_DIR

srun -n $SLURM_NNODES --tasks-per-node=1 mkdir /scratch/nsb37/${SLURM_JOB_ID}
srun -n $SLURM_NNODES --tasks-per-node=1 mkdir /scratch/nsb37/${SLURM_JOB_ID}/TMPDIR
srun -n $SLURM_NNODES --tasks-per-node=1 cp dice.dat /scratch/nsb37/${SLURM_JOB_ID}
srun -n $SLURM_NNODES --tasks-per-node=1 cp FCIDUMP /scratch/nsb37/${SLURM_JOB_ID}

scratch=/scratch/nsb37/${SLURM_JOB_ID}
cd $SLURM_SUBMIT_DIR

ls

echo "Starting job $SLURM_JOBID"
echo

module purge
module load mkl/64/2017/0/4
module load gcc/4.8.3
module load anaconda/python2/5.3.0
module load icc/64/2016/4/258
module load mpi/openmpi/intel16/2.0.2
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/nsb37/local/boost_1_66_0_mpi_vmc/lib/

cd $scratch

export TMPDIR=/scratch/nsb37/${SLURM_JOB_ID}/TMPDIR

mpirun /home/nsb37/Dice_github/Dice dice.dat > dice.out

echo 

srun -n $SLURM_NNODES --tasks-per-node=1 cp dice.out $SLURM_SUBMIT_DIR
srun -n $SLURM_NNODES --tasks-per-node=1 cp spin* $SLURM_SUBMIT_DIR
srun -n $SLURM_NNODES --tasks-per-node=1 cp spatial* $SLURM_SUBMIT_DIR

qstat -f $SLURM_JOBID
